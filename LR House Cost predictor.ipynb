{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f707c385",
   "metadata": {},
   "source": [
    "Building a House Price Prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4129b",
   "metadata": {},
   "source": [
    "Improt all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac8a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83434dac",
   "metadata": {},
   "source": [
    "SECTION - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb7edee",
   "metadata": {},
   "source": [
    "Load all the csv files dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5112286",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv(\"train.csv\")\n",
    "    print(\"Dataset loaded\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train.csv' not found. Please place the dataset in the correct folder/working directory.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a19ea9",
   "metadata": {},
   "source": [
    "Initial data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f50541",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The dataset has {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(f\"\\nFirst 5 rows and {df.shape[1]} columns of the dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\n---- Dataset information (data types and non-null counts) ----\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce7ee2",
   "metadata": {},
   "source": [
    "SECTION - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49025a75",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the original distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[\"SalePrice\"], kde=True)\n",
    "plt.title(\"Distribution of SalePrice (Original)\")\n",
    "plt.xlabel(\"Sale Price ($)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "print(f\"Skewness of original SalePrice: {df['SalePrice'].skew():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf73732",
   "metadata": {},
   "source": [
    "Skewness is more, we will apply log to make it symmetric. \n",
    "As for low it is not low but for high it is not that high. \n",
    "We use log1p not log coz log(0) = -infinity. log1p(x) = log(1+x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d41ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SalePrice_Log\"] = np.log1p(df[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the log-transformed distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df[\"SalePrice_Log\"], kde=True, color=\"green\")\n",
    "plt.title(\"Distribution of SalePrice (Log-Transformed)\")\n",
    "plt.xlabel(\"Log of Sale Price\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "print(f\"Skewness of log-transformed SalePrice: {df['SalePrice_Log'].skew():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4752a6af",
   "metadata": {},
   "source": [
    "Now we will plot loged price with other variables to see how they interact with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# price vs square footage\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df[\"GrLivArea\"], y=df[\"SalePrice_Log\"])\n",
    "plt.title(\"GrLivArea vs. Log-Transformed SalePrice\")\n",
    "plt.xlabel(\"Above Grade Living Area (sq. ft.)\")\n",
    "plt.ylabel(\"Log of Sale Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49631692",
   "metadata": {},
   "source": [
    "The plot shows a clear positive linear relationship [as size increase so does the logPrice], which is good for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbee0b66",
   "metadata": {},
   "source": [
    "SECTION - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da242568",
   "metadata": {},
   "source": [
    "Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d40204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We check for missing values in our selected predictor columns.\n",
    "selected_features_for_check = [\n",
    "    \"GrLivArea\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"FullBath\",\n",
    "    \"HalfBath\",\n",
    "    \"BsmtFullBath\",\n",
    "    \"BsmtHalfBath\",\n",
    "]\n",
    "print(\"\\n--- Missing Value Check ---\")\n",
    "print(df[selected_features_for_check].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6e70a3",
   "metadata": {},
   "source": [
    "No missing data found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80238a2a",
   "metadata": {},
   "source": [
    "We combine the four bathroom-related columns into a single, more meaningful feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a6d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TotalBathrooms\"] = (\n",
    "    df[\"FullBath\"]\n",
    "    + 0.5 * df[\"HalfBath\"]\n",
    "    + df[\"BsmtFullBath\"]\n",
    "    + 0.5 * df[\"BsmtHalfBath\"]\n",
    ")\n",
    "print(\"\\n'TotalBathrooms' feature created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd533b",
   "metadata": {},
   "source": [
    "Now we have 4 coloums to manage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14b2ca7",
   "metadata": {},
   "source": [
    "Dataset Partitioning: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4c0d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define our final set of features (X) and the target variable (y).\n",
    "features = [\"GrLivArea\", \"BedroomAbvGr\", \"TotalBathrooms\"]\n",
    "target = \"SalePrice_Log\"\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print(f\"\\nData split into training and testing sets:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecdd411",
   "metadata": {},
   "source": [
    "Feature Scaling: This is important because our features are on different scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faba2df4",
   "metadata": {},
   "source": [
    "Comparing Apples and Oranges. \n",
    "GrLivArea (Square Footage) is the History Exam (values in the thousands). \n",
    "BedroomAbvGr (Number of Bedrooms) is the Math Exam (values like 2, 3, 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f31734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train) #It calculates the necessary statisticsâ€”the mean and the standard deviation.\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nFeatures scaled successfully using StandardScaler.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ea687b",
   "metadata": {},
   "source": [
    "SECTION - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4545d641",
   "metadata": {},
   "source": [
    "Training the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9af41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"\\nLinear Regression model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c133cca5",
   "metadata": {},
   "source": [
    "Model Interpretation and Coefficients [Y = m*X + b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d15d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Interpretation: It is the baseline log-price.\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "\n",
    "print(\"Coefficient: It represents the expected change in the log-price for a one standard deviation increase in that feature, holding others constant.\")\n",
    "coefficients = pd.DataFrame(model.coef_, features, columns=[\"Coefficient\"])\n",
    "print(coefficients)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541b6ad",
   "metadata": {},
   "source": [
    "Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf03f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = model.predict(X_test_scaled) # predictions on log scale.\n",
    "y_pred_dollars = np.expm1(y_pred_log) # un-logging the predicted values.\n",
    "\n",
    "y_test_dollars = np.expm1(y_test) # the original test values.\n",
    "\n",
    "print(\"\\nPredictions made on the test set and converted back to dollar amounts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee855d9",
   "metadata": {},
   "source": [
    "SECTION - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c74de1",
   "metadata": {},
   "source": [
    "Model Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c42f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on the log scale (as the model was trained)\n",
    "r2_log = r2_score(y_test, y_pred_log)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_test, y_pred_log))\n",
    "\n",
    "print(f\"R-squared (Log Scale): {r2_log:.4f}\")\n",
    "print(f\"R-squared_score: The model's features (square footage, bedrooms, etc.) explains {r2_log*100:.2f}% of the variance in the log-transformed sale prices.\")\n",
    "print(f\"\\nRMSE (Log Scale): {rmse_log:.4f}\")\n",
    "\n",
    "# Evaluation on the original dollar scale for interpretability\n",
    "rmse_dollars = np.sqrt(mean_squared_error(y_test_dollars, y_pred_dollars))\n",
    "\n",
    "print(f\"\\nRMSE (Dollar Scale): ${rmse_dollars:,.2f}\")\n",
    "print(f\"On average, its predictions are off by about ${rmse_dollars:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acf6f1",
   "metadata": {},
   "source": [
    "The difference between actual and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4917b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We calculate the residuals (the difference between actual and predicted values).\n",
    "residuals = y_test - y_pred_log\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# A. Homoscedasticity Check: Residuals vs. Predicted Values\n",
    "# We look for a random cloud of points around y=0 with no clear pattern.\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x=y_pred_log, y=residuals)\n",
    "plt.axhline(y=0, color=\"r\", linestyle=\"--\")\n",
    "plt.title(\"Residuals vs. Predicted Values\")\n",
    "plt.xlabel(\"Predicted Log(SalePrice)\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "\n",
    "# B. Normality of Residuals Check: Q-Q Plot\n",
    "# We look for points falling along the 45-degree diagonal line.\n",
    "plt.subplot(1, 2, 2)\n",
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q Plot of Residuals\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768f88a",
   "metadata": {},
   "source": [
    "Diagnostic Checks Summary\n",
    "1. Homoscedasticity Plot: The points appear randomly scattered around the zero line, suggesting the assumption of constant variance (homoscedasticity) is reasonably met. There is no obvious cone shape.\"\n",
    "2. Q-Q Plot: The points fall mostly along the diagonal line, indicating that the residuals are approximately normally distributed, satisfying another key assumption of linear regression."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
